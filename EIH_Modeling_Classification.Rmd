---
title: "EIH prediction using AI approaches"
author: "FÃ©lix Boudry"
date: "`r Sys.Date()`"
documentclass: article
classoption: oneside
lang: en-US
output:
  html_document:
    toc: yes
    number_section: yes
    fig_caption: yes
    keep_md: yes
params:
  new_models:
    label: "Compute new models?"
    value: true
  seed:
    label: "Seed:"
    value: 42
    input: numeric
  data:
    label: "Input dataset:"
    value: "./Data/summary.csv"
    input: file
  predict_label:
    label: "Feature to predict:"
    value: c("eih")
    input: text
  excluded_variables:
    label: "Features to exclude from clustering and training:"
    value: c("saturation_rest", "saturation_end", "saturation_delta", "subject", "eih_severity")
    input: text
---

```{r Setup, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  error = TRUE,
  message = FALSE,
  warning = FALSE
)
reticulate::use_virtualenv(virtualenv = "EIH")
project_seed <- params$seed
set.seed(seed = project_seed)

# Import libraries
source("./Scripts/Functions.R")
library(data.table)
library(tidyverse)
library(factoextra)
library(clusplus) # https://github.com/pablo14/clusplus
library(caret)
library(gbm)
library(lightgbm)
library(reticulate)
library(shapviz)
library(magrittr)
library(gridExtra)
library(psych)
library(fs)
library(tools)
library(CatEncoders)

# Create a folder to save results
analysis_date <- format(Sys.time(), "%Y-%m-%d_%H.%M.%S")
dir_create(path = paste0("Output/", analysis_date))

## Parsing and evaluating strings used as parameters to be used as code
excluded_variables <-
  eval_knit_param(params$excluded_variables)
predict_label <-
  eval_knit_param(params$predict_label)

## Manual parameters for the analysis
cluster_number <- 2
cluster_number_names <- "two"
ml_split <- 0.8
optuna_trials <- 25
lgbm_rounds <- 45
xgboost_rounds <- 45
```

```{r Import & scripts, include=FALSE}
# Import selected data set creating imported_data_names and imported_data
imported_data <-
  fread(input = params$data,
        na.strings = c("NA", "na", "", "Inf", "-Inf"))

# Source scripts for analysis
dir_create(path = paste0("Models/"))
no_num_colnames <- # Columns that will be encoded
  dplyr::select_if(imported_data, negate(is.numeric)) %>%
  colnames()
antrop_data <- imported_data[, c("age", "height", "weight", "train_years", "train_volume")]
analysis_data <- imported_data %>%
  df_encode() %$%
  encoded_data %>%
  clean_dataset() %>%
  round(digits = 4)
names(convert_dic) <-
  no_num_colnames # Naming encoding list elements
source("./Scripts/Unsupervised.R")
source("./Scripts/Supervised.R")
```

# EIH prediction

This report shows the classifications achieved using various methods to detect
EIH subjects.

# Material and methods

## Subjects

```{r}
describe(x = antrop_data, na.rm = T) %>%
  round() %>%
  select(c("mean", "sd", "median", "min", "max")) %>%
  my_table(
    caption = paste0(
      "<center><strong>Anthropological values (n = ",
      nrow(analysis_data) ,
      ")</center></strong>"
    )
  )
```

# Results

## Unsupervised learning

The unsupervised approach is based on algorithms that don't need labels to
create a classification. This mainly include clustering algorithms such as
k-means and hierarchical clustering.

### K-means clustering

```{r fig.align='center'}
kclust_graph
kclust_coord
kclust_confusion$table %>%
  my_table(caption = "<center><strong>K-means confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
kclust_confusion$overall %>%
  my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
kclust_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)
```

### Hierarchical agglomerative clustering

```{r fig.align='center'}
hclust_bu_graph
hclust_bu_confusion$table %>%
  my_table(caption = "<center><strong>HC agglomerative confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
hclust_bu_confusion$overall %>% my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
hclust_bu_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)
```

### Hierarchical divisive clustering

```{r fig.align='center'}
hclust_td_graph
hclust_td_confusion$table %>%
  my_table(caption = "<center><strong>HC divisive confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
hclust_td_confusion$overall %>% my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
hclust_td_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)
```

## Supervised learning

The supervised approach, compared to the unsupervised one, require labels to try
a classification and the correct the classification process and criteria. In
this work we used LGBM and XGBoost and decision tree based methods and a Dense
and a NODE model as neural network approaches.

### LightGBM

The model computed with the best parameters of this trial has the following
metrics:

```{r fig.align='center'}
# Confusion tables
lgbm_confusion$table %>%
  my_table(caption = "<center><strong>LGBM confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
lgbm_confusion$overall %>% my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
lgbm_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)

# SHAP plots
lgbm_shap_plot %>%
  walk(print)
# Features tables
feature_data <- imported_data %>%
  as.data.frame() %>%
  select(c(
    gsub("\\.", "/", lgbm_shap_plot$importance_plot$data$feature),
    predict_label
  ))

tab1 <-
  scipub::FullTable1(data = feature_data,
                     strata = predict_label,
                     es_col = FALSE)

my_table(tab1$table) %>%
  kableExtra::footnote(general = tab1$caption, general_title = "")

describeBy(
  x = feature_data,
  group = feature_data[, predict_label],
  mat = TRUE,
  digits = 2,
  IQR = TRUE,
  quant = c(0.25, 0.5, 0.75),
  skew = FALSE,
  ranges = T
) %>%
  my_table()
```

### XGBoost

The model computed with the best parameters of this trial has the following
metrics:

```{r fig.align='center'}
# Confusion tables
xgboost_confusion$table %>%
  my_table(caption = "<center><strong>XGBoost confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
xgboost_confusion$overall %>% my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
xgboost_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)

# SHAP plots
xgboost_shap_plot %>%
  walk(print)

# Features tables
feature_data <- imported_data %>%
  as.data.frame() %>%
  select(c(
    gsub("\\.", "/", xgboost_shap_plot$importance_plot$data$feature),
    predict_label
  ))

tab1 <-
  scipub::FullTable1(data = feature_data,
                     strata = predict_label,
                     es_col = FALSE)

my_table(tab1$table) %>%
  kableExtra::footnote(general = tab1$caption, general_title = "")

describeBy(
  x = feature_data,
  group = feature_data[, predict_label],
  mat = TRUE,
  digits = 2,
  IQR = TRUE,
  quant = c(0.25, 0.5, 0.75),
  skew = FALSE,
  ranges = T
) %>%
  my_table()
```

### PyTorch Tabular NODE

```{r fig.align='center'}
# Confusion tables
node_confusion$table %>%
  my_table(caption = "<center><strong>NODE NN confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
node_confusion$overall %>% my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
node_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)
```

### PyTorch Tabular GANDALF

```{r fig.align='center'}
# Confusion tables
gandalf_confusion$table %>%
  my_table(caption = "<center><strong>GANDALF NN confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
gandalf_confusion$overall %>% my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
gandalf_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)
```

### PyTorch Tabular DANET

```{r fig.align='center'}
# Confusion tables
danet_confusion$table %>%
  my_table(caption = "<center><strong>GANDALF NN confusion matrix</center></strong>", row.names = TRUE) %>%
  kableExtra::column_spec(1, bold = TRUE)
danet_confusion$overall %>% my_table(caption = "<center><strong>Overall metrics</center></strong>", col.names = NULL)
danet_confusion$byClass %>%
  my_table(caption = "<center><strong>Metrics by class</center></strong>", col.names = NULL)
```

# Models comparison

```{r fig.align='center'}
result_list <-
  lst(
    results_lgbm = lst(
      lgbm_confusion$overall[["Accuracy"]],
      lgbm_confusion$overall[["Kappa"]],
      lgbm_confusion$byClass[["F1"]],
      lgbm_confusion$byClass[["Precision"]],
      lgbm_confusion$byClass[["Recall"]]
    ),
    results_xgboost = lst(
      xgboost_confusion$overall[["Accuracy"]],
      xgboost_confusion$overall[["Kappa"]],
      xgboost_confusion$byClass[["F1"]],
      xgboost_confusion$byClass[["Precision"]],
      xgboost_confusion$byClass[["Recall"]]
    ),
    results_node = lst(
      node_confusion$overall[["Accuracy"]],
      node_confusion$overall[["Kappa"]],
      node_confusion$byClass[["F1"]],
      node_confusion$byClass[["Precision"]],
      node_confusion$byClass[["Recall"]]
    ),
    results_gandalf = lst(
      gandalf_confusion$overall[["Accuracy"]],
      gandalf_confusion$overall[["Kappa"]],
      gandalf_confusion$byClass[["F1"]],
      gandalf_confusion$byClass[["Precision"]],
      gandalf_confusion$byClass[["Recall"]]
    ),
    results_danet = lst(
      danet_confusion$overall[["Accuracy"]],
      danet_confusion$overall[["Kappa"]],
      danet_confusion$byClass[["F1"]],
      danet_confusion$byClass[["Precision"]],
      danet_confusion$byClass[["Recall"]]
    )
    
  )

do.call(rbind, result_list) %>%
  `colnames<-`(c("Accuracy", "Kappa", "F1", "Precision", "Recall")) %>%
  `rownames<-`(c("LGBM", "XGBoost", "NODE", "GANDALF", "DANET")) %>%
  my_table()
```

# Knitting parameters

The following parameters were used as input to create this report:

```{r Infos}
params %>% do.call(what = rbind, args = .) %>% my_table()
```

```{r End_tasks, include=FALSE}
result_save()
```
